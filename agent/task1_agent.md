# 智能体组第一次自学任务——知识图谱与智能问答 Agent

## 任务概述

本任务旨在引导你深入学习知识图谱的构建、结合大语言模型进行知识抽取与推理，并最终搭建一个基于LlamaIndex框架的智能问答Agent。你将通过实践掌握从非结构化文本中提取知识、构建结构化知识图谱、进而实现高效智能检索与对话的关键技术。

## 学习目标

- 理解知识图谱、因果关系三元组、Graph RAG和知识图谱社区等核心概念。
- 掌握使用LlamaIndex框架构建智能体工作流的方法。
- 实践PDF解析、LLM驱动的知识抽取技术。
- 掌握Neo4j图数据库的Docker部署与知识图谱构建。
- 理解知识图谱社区化与向量化的方法。
- 搭建基于Graph RAG的智能检索工具和遵循ReAct范式的智能体。

## 前置条件/工具学习

- **熟悉以下工具的基本使用：**
    - **Cursor:** 一款AI辅助编程工具，提升开发效率。[工具-AI coding工具：Cursor IDE （ Trae ）](./linked_notes/工具-AI%20coding工具：Cursor%20IDE%20（%20Trae%20）.md)
    - **Git:** 版本控制工具，用于代码管理与协作。[工具-Git教程](./linked_notes/工具-Git教程.md)
    - **CherryStudio API Chat工具:** 接入和测试各种API的便捷工具，尤其是LLM API。[工具-AI chat工具：CherryStudio+云雾API调用](./linked_notes/工具-AI%20chat工具：CherryStudio+云雾API调用.md)

## 任务内容

### 第一部分：核心概念学习

#### 1. 知识图谱 (Knowledge Graph)

- **定义与作用：** 理解知识图谱如何通过实体、关系和属性来结构化地表示现实世界知识，及其在语义查询、推荐系统和智能问答中的应用。
- **组成要素：** 深入理解实体、关系的基本构成，以及三元组（Subject-Predicate-Object）作为知识图谱核心表示形式。

#### 2. 因果关系三元组 (Causal Triples)

- **定义：** 学习如何识别和表示事件或概念之间的因果联系，例如 `<原因, 导致, 结果>`。
- **重要性：** 探究因果关系三元组如何增强知识图谱的推理能力，使其不仅能回答“是什么”，还能回答“为什么”和“会怎样”。

#### 2.999. RAG

通过增强检索生成来构建一个知识库，具体技术需要用到嵌入模型，大一同学可以回顾一下Comsen招新测试任务4.

#### 3. Graph RAG (Graph Retrieval Augmented Generation)

- **定义：** 学习将知识图谱与检索增强生成（RAG）技术相结合的原理，为大语言模型提供更准确、更丰富的上下文信息。
- **核心思想：** 理解Graph RAG如何利用图谱的结构化知识和语义信息，克服传统RAG在信息召回和推理方面的局限。

#### 4. 知识图谱社区 (Knowledge Graph Community)

- **定义：** 学习知识图谱中的社区概念，即图中连接紧密的实体子集。
- **应用：** 了解社区发现算法的原理，以及社区结构如何帮助我们理解图谱的宏观结构、进行子图分析和生成有意义的社区摘要。

#### 5. 推荐学习资源

- **知识图谱入门：** 论文《From Local to Global: A Graph RAG Approach to Query-Focused Summarization》
- **Graph RAG：** 搜索“Graph RAG”相关技术博客、论文或LlamaIndex官方文档中关于Graph RAG的介绍。
- **Neo4j 官方文档：** 了解Neo4j图数据库的基础概念、Cypher查询语言和图算法库（GDS）。
- **LlamaIndex 官方文档：** 深入学习LlamaIndex框架在Agent、Tool、Graph RAG等方面的功能。

---

### 第二部分：数据处理工作流构建

本部分旨在构建一个数据处理工作流，将非结构化论文PDF转化为结构化的知识三元组，为知识图谱的构建做准备。

#### 0. 环境配置

安装依赖，统一使用 Python version = 3.11 的 conda 虚拟环境

可能会用到的依赖有：llamaindex, neo4j , pdf处理有关的库……

#### 1. PDF文献解析与JSON格式化

**目标：** 将大量的科研论文PDF文件解析为易于处理的JSON格式文本数据。

**要求：**

- **输入：** 模拟您将提供一个包含50+篇不同来源论文文献的PDF数据集。数据集在 `./agent/datas`
- **输出：** 实现一个脚本，能够将每个PDF文件解析成一个独立的JSON文件。请自行设计JSON文件的结构，但需包含文本块（如段落）及其必要的元数据（例如：原始页码、所属章节标题等），以便后续知识抽取和溯源。
- **技术栈：** 建议使用Python库，如 `PyMuPDF (fitz)` 或 `pdfminer.six` 进行PDF文本、图表元信息和文档结构的提取。

#### 2. LLM驱动的知识三元组抽取

**目标：** 利用大语言模型从解析后的JSON文本块中抽取实体及其关系，形成因果关系三元组。

**要求：**

- **输入：** 上一步生成的JSON格式文本数据。
- **过程：**
    1. **智能体工作流设计：** 基于LlamaIndex框架，设计一个智能体工作流，能够从50+个JSON文件中随机选择10个作为本次任务的样本。
    2. **文本块遍历与LLM调用：** 遍历这10个JSON文件中的每一个文本块。对于每个文本块，调用一个大型语言模型API。
    3. **提示词工程：** 精心设计用于知识抽取的提示词（Prompt Engineering），确保LLM能够准确识别文本中的实体，并抽取出它们之间的因果关系三元组。例如，可以引导LLM输出类似 `{"subject": "锂离子电池", "predicate": "具有优势", "object": "高安全性", "source_text_id": "..."}` 的JSON格式结果。
    4. **知识溯源：** 确保每个抽取出的三元组都能关联回其原始文本块的ID或位置，方便后续进行知识溯源。
- **输出：** 包含抽取出的三元组及其元数据的JSON文件集合。
- **技术栈：** Python, LlamaIndex, LLM API (可选用 `云雾` 或 `OpenRouter`)。

---

### 第三部分：知识图谱构建

#### 1. Neo4j部署

**目标：** 使用Docker容器技术快速部署Neo4j图数据库。

**要求：**

- 成功地通过Docker部署一个Neo4j实例，并确保可以通过Web界面（Neo4j Browser）或Neo4j驱动程序进行访问和操作。

#### 2. 知识图谱构建

**目标：** 将第二部分抽取的所有三元组导入Neo4j，构建一个结构化的知识图谱。

**要求：**

- **输入：** 第二部分抽取的所有三元组JSON数据。
- **过程：**
    1. **图谱模式（Schema）设计：** 参考您项目报告中图4所示的“构建的知识图谱”示例及“图谱模式设计”章节，设计图谱的节点类型、关系类型及其属性。特别注意分层标签体系（如“材料层”、“器件层”、“系统层”、“应用场景层”）和溯源关系（FROM）。
    2. **数据导入脚本：** 编写Python脚本，利用Neo4j的Python驱动或Cypher查询语句，将三元组数据批量、高效地导入到Neo4j数据库中。确保实体被创建为节点，关系被正确连接，并附带所有相关属性。
    3. **图谱结构验证：** 构建后的知识图谱应能够通过Neo4j Browser进行可视化展示，并能查询出与项目报告中图4类似的结构特征，包括多层级标签与清晰的溯源路径。
- **技术栈：** Python, Neo4j, Cypher查询语言, Docker。

最终构建的知识图谱在Neo4j面板展示出的效果如下
![image.png](https://hysinoss-1334037784.cos.ap-shanghai.myqcloud.com/20251117201108321.png)


---

### 第四部分：Graph RAG 构建

**目标：** 对构建好的知识图谱进行社区化和向量化处理，形成一个可用于检索增强的Graph RAG。

**要求：**

- **知识图谱社区化：**
    1. **社区发现：** 使用Neo4j图数据科学库（Graph Data Science Library, GDS）或其他图算法库，对您构建的知识图谱进行社区发现，例如使用Louvain或Label Propagation算法，识别出不同的知识社区。
    2. **社区摘要生成：** 对于识别出的每个社区，设计一种方法（例如，提取社区中最核心的实体和关系，或者利用LLM对社区内的文本片段进行总结），生成该社区的简洁摘要，以捕捉其核心主题。
- **知识图谱向量化：**
    1. **节点/关系嵌入：** 选用合适的图嵌入算法（直接使用LlamaIndex提供的LLM对节点和关系描述进行嵌入）（用Embedding模型），将图谱中的所有节点和关系转换为高维向量表示。
    2. **向量数据库集成：** 将这些生成的向量及其对应的节点/关系ID存储到外部向量数据库中（如Qdrant），或利用Neo4j自身的向量索引功能。
- **技术栈：** Python, Neo4j (GDS), LlamaIndex, 向量数据库（如Qdrant）。

---

### 第五部分：智能检索工具构建

**目标：** 构建一个智能工具，能够根据用户提问的关键词在Graph RAG中高效进行检索和推理。

**要求：**

- **工具功能：**
    1. **接收查询：** 设计一个`Tool`函数，接收用户输入的自然语言查询（query）或关键词。
    2. **混合检索策略：** 该工具应结合语义相似度检索（利用向量数据库）和图结构路径搜索（利用Neo4j）的优势，从Graph RAG中召回最相关的知识片段。
    3. **社区摘要与检索：** **重点关注**如何将第四部分生成的社区摘要信息整合到检索策略中。例如，在初步召回相关社区后，优先从这些社区的摘要中提取信息或进一步细化搜索。
    4. **图推理：** 工具应具备一定的图推理能力，例如通过遍历图谱路径，找出与查询关键词相关的实体、它们之间的多跳关系，或所属的知识社区。
    5. **结果格式化：** 返回结构化的检索结果，其中包含相关实体、关系、社区摘要及知识溯源信息，以便上层智能体消费。
- **技术栈：** Python, LlamaIndex (Tool), Neo4j, 向量数据库。
- 将这个Tool构建成LlamaIndex的工具。

---

### 第六部分：ReAct智能体工作流构建

**目标：** 构建一个基于LlamaIndex的ReAct智能体工作流，实现与论文内容的交互式对话。

**要求：**

- **智能体框架：** 整个工作流必须全程使用LlamaIndex智能体框架。
- **ReAct范式：** 智能体应遵循ReAct（Reasoning and Acting）决策范式。即，智能体在处理用户提问时，能够进行“思考”（Reasoning），然后“行动”（Acting）调用外部工具，并根据工具返回的观测结果再次“思考”并决定下一步行动，直到得出最终答案。
- **工作流设计：**
    1. **用户交互：** 智能体能够接收用户关于论文内容的自然语言提问。
    2. **多步Thinking：** 智能体需展现出多步思考的能力，例如将复杂问题分解为子问题，逐步调用工具获取信息，并整合信息形成答案。
    3. **工具调用：** 智能体能够智能地调用第五部分构建的“智能检索工具”，获取知识图谱中的相关信息。
    4. **对话能力：** 最终智能体能够基于所获取的知识，流畅、准确地回答用户关于论文内容的问题，并能够提供知识来源（溯源）以增强可信度。
- **技术栈：** Python, LlamaIndex (Agent, ReAct Agent), 第五部分构建的智能检索工具, LLM API。

---

## 提交要求

### 提交内容包含：

1. **实践报告**（Markdown 格式）
    
    - 前置工具（Cursor, Git, CherryStudio API Chat）学习心得及关键操作截图。
    - PDF解析与JSON格式化过程的详细描述与两个示例JSON输出。
    - LLM驱动三元组抽取的提示词设计、智能体工作流描述及至少五个抽取示例（JSON格式）。
    - Neo4j部署截图、知识图谱模式设计、导入脚本关键代码片段及构建后的图谱可视化截图（类似项目报告图4）。
    - Graph RAG社区发现与向量化方案描述（包括所选算法、参数及Rationale）。
    - 智能检索工具的设计思路、功能描述（特别是社区摘要和检索策略）及至少三个检索示例。
    - ReAct智能体工作流的设计思路、一个完整的思考链（Chain of Thought）示例及智能体与论文对话的演示截图（至少两轮问答）。
    - 在完成任务过程中遇到的主要问题、解决方案及个人心得体会。
2. **代码文件**
    
    - 所有编写的Python脚本（包括PDF解析、三元组抽取、Neo4j导入、Graph RAG构建、智能检索工具代码、ReAct Agent代码）。
    - 用于Neo4j部署的 `docker-compose.yml` 或 `Dockerfile` 文件。
    - `requirements.txt` 文件，列出所有Python项目依赖库及其版本。
3. **数据文件**
    
    - 用于演示的少量PDF源文件（建议5-10篇）。
    - LLM抽取的三元组JSON示例文件。
    - 您在第二部分自行定义的JSON格式规范说明。
    - 如果使用了自定义数据集或公开数据集，请提供网盘链接，**切勿直接上传数据集到GitHub**。

### 提交方式：

注册一个Github账号，自己建一个在线Git仓库，将代码上传上去，并保证代码库的权限为Public，然后提交该在线仓库的链接。提交方式后续再通知，不必着急提交。